"""
FetchesLatestAgent - Fetches the latest stories from Hacker News using the public API.

Auto-generated by LearnNewAgent on 2026-02-04 22:39.
"""

import json
import urllib.request
from openrappter.agents.basic_agent import BasicAgent


class FetchesLatestAgent(BasicAgent):
    """
    Fetches the latest stories from Hacker News using the public API.
    """
    
    HN_API = "https://hacker-news.firebaseio.com/v0"
    
    def __init__(self):
        self.name = 'FetchesLatest'
        self.metadata = {
            "name": self.name,
            "description": "Fetches the latest Hacker News stories. Returns titles, URLs, scores, and comment counts.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Optional: 'top', 'new', 'best', or a number for count."
                    },
                    "count": {
                        "type": "integer",
                        "description": "Number of stories to fetch (default: 10, max: 30)."
                    }
                },
                "required": []
            }
        }
        super().__init__(name=self.name, metadata=self.metadata)
    
    def perform(self, **kwargs):
        """Fetch latest Hacker News stories."""
        query = kwargs.get('query', '')
        count = kwargs.get('count', 10)
        story_type = 'top'
        
        # Parse query for type or count
        if query:
            q = query.lower()
            if q in ['top', 'new', 'best', 'ask', 'show', 'job']:
                story_type = q
            else:
                try:
                    count = int(query)
                except ValueError:
                    pass
        
        count = min(max(1, count), 30)
        
        try:
            # Get story IDs
            url = f"{self.HN_API}/{story_type}stories.json"
            with urllib.request.urlopen(url, timeout=10) as resp:
                ids = json.loads(resp.read().decode())[:count]
            
            # Fetch each story
            stories = []
            for sid in ids:
                try:
                    with urllib.request.urlopen(f"{self.HN_API}/item/{sid}.json", timeout=5) as resp:
                        item = json.loads(resp.read().decode())
                        if item:
                            stories.append({
                                "title": item.get("title", "No title"),
                                "url": item.get("url", f"https://news.ycombinator.com/item?id={sid}"),
                                "score": item.get("score", 0),
                                "by": item.get("by", "unknown"),
                                "comments": item.get("descendants", 0)
                            })
                except:
                    continue
            
            return json.dumps({
                "status": "success",
                "type": story_type,
                "count": len(stories),
                "stories": stories
            })
            
        except Exception as e:
            return json.dumps({
                "status": "error", 
                "message": str(e)
            })
